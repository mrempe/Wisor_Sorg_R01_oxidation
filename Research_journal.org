My notes to self on Wisor/Sorg grant -*- mode: org -*-
Summer 2018-

* Tuesday, May 22, 2018
A possible main question I would like to address was presented to me by Jonathan in an email 3.1.18:  "How would an increase in GABA affect network 
properties, especially gamma activity?".  Here is a proposed chain of logic:
sleep deprivation -> increased parvalbumin (PV) -> increased GABA (inhibition onto pyramidal neurons) -> cognitive deficits after sleep deprivation

This seems to imply that we will need a rather detailed network. Many have been published including by XJ Wang, and Bill Lytton.  One of the most 
mathematical and detailed dates back to the 1970s: "The brain wave equation: a model for the EEG" by Paul Nunez. This seems way too complicated for what 
we want to do.  

:NOTE: the model could focus on any one or more of the arrows above

My model will need:
- to be able to generate gamma activity
- have GABA as an input
- to display different sleep states (and therefore include processes S and C?)
- to tie gamma activity to sleep (maybe.  Figure 1 in the grant)


How does increasing GABA cause a reduction in gamma power?  Grant figure 1.   Wang and Buzsaki 1996 include a figure (figure 12) where they 
vary g_syn which is the maximal conductance of GABA synapses.   


* Wednesday, May 23, 2018
I'm reading a book chapter by Nunez about complexities of EEG modeling.  I think we need to take a high level approach.  Wang and Buzsaki 1996 may be
about as complicated as we would want to go.  I would need to include effects of sleep and possibly Circadian on that model, perhaps. 

Another simpler approach:  Jonathan and Barb show that gamma activity declines with increasing sleep need.  Perhaps I could model it just like 
Process S just backwards.  I would find the optimal time constants Ti and Td to fit the data (spontaneous quiet wake intervals of 5 minutes or more?) and quantify
the changes in gamma activity based on whether or not PNNs were depleted or not.   

* Thursday, May 24, 2018
Reading through the grant proposal again.  Basic terms: :redox: (short for reduction-oxidation reaction) redox reactions involve the transfer of 
electrons between chemical species. :oxidation: is the loss of electrons or an increase in oxidation state and :reduction: is the gain of electrons 
or a decrease in oxidation state.  For example, during combustion of wood, oxygen from the air is reduced, gaining electrons from carbon which is oxidized.  
Rust and fire are two examples of redox reactions.  

:Question: Are we interested in increases in gamma activity only during quiet wake?  What about during SWS?  

I keep seeing "neural mass model" show up.  May be worth looking into.  

Key paper:  Wendling et al 2002 seems to be a really important paper for this type of modeling.  tons of citations and many variations off the original model. 
Also take a careful look at Jia and Kohn JNeurosci 2013.  They wrote the primer on gamma rhythms.  

* Wednesday, May 30, 2018
Another key paper is Costa et al 2016. They connect a mutual inhibition model like mine (from Victoria and Cecilia) to populations of pyramidal cells and inhibitory 
cells (PV interneurons?) and generate realistic EEG signals out of the model.  Does not include circadian effects, but does include homeostat.  I would need to modify 
this framework to work for rodent sleep (rather than human) and modify to help us understand PNN

* Friday, June 1, 2018
This week I was asked to help debug some of Jonathan's code for Michelle and in doing so I made significant improvements to the universalEdfLoader function. 
Also, I spent today speeding up the autoscoring code that uses .edf as input.  I made many significant improvements in efficiency including calling pwelch only 
once instead of in a loop. Overall computation time was reduced from over a minute to less than 30 seconds.  


* Monday, June 11, 2018
I've been working on implementing the Costa et al 2016 model.  I was finally able to compile his mex code, but it crashes matlab partway through the run.  I emailed 
Michael and he responded saying that he no longer works in academia and that he may have broken the code.  He will check into it and get back to me. 

Meanwhile I have coded up the sleep/wake portion of the model and it now seems to work.  
:NOTE: the output of the sleep/wake model is not dependent on the parameters tau_E, tau_G, and tau_A.  The values in the C++ code are different than those in the paper, but
choosing either value doesn't seem to affect the output at all.  


* Wednesday, June 13, 2018
I now have the Costa model working in MATLAB without noise.  The model takes about an hour to run, but output looks good.  With noise is another question.  I have tried 
several approaches and none seem to work.  Running a 24 simulation with noise crashed matlab after about 8 hours (24 G of memory).  Running it on just one hour
still takes a while and gives me much noisier output than Costa was getting.  

I've been thinking about whether this is a true SDE or not.  I don't think so.  An SDE has the noise term depending on one or more of the dependent variables.  For me the 
noise is just added to two variables.  I'm not sure I need a SDE solver, but I'm also not sure why adding noise makes the computation so slow and so unstable.

:UPDATE: this is an SDE and I do need an SDE solver.  I've spent quite a bit of time reading about SDE solvers.    

:idea: Maybe I could set up a big vector of random numbers with correct mean and SD and just add one of these numbers in to the update of the two variables each time step.
Make the vector of length so that if the minimum step size were used throughout simulation we would have enough random numbers for every time step.  
I tried this with my fixed-step solver and it did not work. Simulation outputs did not look stochastic and were not even close to the correct behavior (compared
to the w/o noise case)

* Monday, June 18, 2018

:PROBLEM:  one thing to think about:  if things like gamma power come only from the stochastic nature of the simulations, how do I reliably measure gamma power since 
each simulation will be different than the others?  Perhaps I could measure gamma for each simulation and then average the gamma power over all simulations.
Run the simulation a few times and check gamma.  Is it about the same each time?      

* Tuesday, June 19, 2018
The implementation I coded up yesterday (due to Chang 1987) seems to have worked.  I ran a 2-hour simulation and it looks good so far.  Except it took 
about 2 hours to simulate two hours of data.  

I'm looking at the SDETools suite to see if it would be faster.  


* Thursday, June 21, 2018
So far it looks as if SDETools is faster, but keep in mind that it is a lower order method.  It's like comparing Forward Euler to RK4.  RK4 has
more function evals and more steps so with the same step size it will be slower, but more accurate. 
:THINK:  what is a fair way to compare the two integrators?  How to I measure accuracy/convergence of a method for SDE? :ONE: :IDEA: check spectral
power.  If it does not change when I make the time step larger, then we're OK.  

I ran my sde solver in Octave in linux and it was MUCH MUCH slower.  sde_euler didn't even run in octave because of too many differences between matlab and Octave. 

Trying octave in windows now.  Much slower.  47 minutes rather than 47 seconds in Matlab.  This was for a simulation of 6 seconds I think. Matlab in Windows is the 
way to go. 

* Friday, June 22, 2018
Tyring to see how Costa gets spectral information for the sleep scoring, or if he does at all.  

It required 49 minutes to run Costa's code for a 24-hr simulation.  That was running Data_Sleep_Transition.m which is what Costa says requires ~1hr.      
Data_Sleep_Epochs() required another minute or so, but it ran without errors.  
Costa's code seems to be running and the data are stored in Data/Timeseries_FULL.mat and Data/Sleep_Epochs.mat.  The script Plot_Timeseries_Full() works 
and replicates figure 7 in their paper.  
:TODO: Write up code to check the spectral power of the output of Costa's output. Did this in the command line using code 
from generate_freq_bands_from_edf.m and something looks wrong.  All the frequency bands seem to behave the same way. All go up during SWS and there 
is more delta power than anything else, all the time, even during wakefulness.  
:TODO: make sure my pwelch calculations are working and the issue is the model output, not my pwelch stuff. Read in some real polysomnography 
data where I know the sleep states and make sure my pwelch code is behaving correctly.   
:TODO: Try running my little implementation for 24 hours to see how long it takes. And make sure output is like Costa's.  

* Monday, June 25, 2018
It doesn't look like Costa uses spectral info at all when it comes to classifying sleep states.  He manually classifies just by looking at the data, I can't see 
that he uses spectral power at all.    

11:20: I plotted the power in delta, theta, and beta freq bins for the experimental data E2697Base, and for the data generated by the Costa model.  Here are some problems:
during wakefulness, for the Costa model, delta power is still higher than theta or beta power.  Delta goes up by a factor of about 40 between baseline and NREMS episodes, but theta seems to just sit there doing nothing.  Theta is lower than delta all the time, no matter which stage.  Theta actually increases a little compared to baseline
during SWS.  During REMS, delta drops significantly, but is still higher than theta or beta


* Tuesday, June 26, 2018
I'm running run_costa_model_using_sde_solver on the Inscopix machine using the GPU.  with dt=0.1 and t=0:dt:60000 it is taking about 3 hours.  Re-run this exact 
simulation on UltraRoss.  I thought it took about 47 seconds.  Also check to see if using the GPU helps at all on Inscopix.  

2:15 Average delta power during first 6 minutes of simulation (using run_costa_model_using_sde_solver.m) is very dependent on step size.  Changing dt from 0.1 ms 
to 1 ms changes averge delta power from 5.5 to 4.3.  

Make a frequency power plot of the output of Costa model (in Data directory) for the first 12 hours.  Then compare that to the same frequency power plot 
made during SWS.  power on vertical axis and frequency on horizontal axis.  

* Wednesday, June 27, 2018
I worked some on the Wendling model today.  The code given on ModelDB works and I computed delta power and alpha power for 100 seconds (10 epochs) during
wakefulness. It looks promising, but this model does not have sleep states, only wake and epilepsy as far as I can tell.  If I am going to be modifying a 
model anyway, I think I would prefer to modify the Costa model and not the Wendling model. 
:HOWEVER: It may be worth looking at how she does noise.  She has a separate function for noise and then uses a regular (as far as I can tell) Euler scheme 
to update the equations. :UPDATE: I don't think this actually works.  She generates a random variable and then does regular Euler.  She's not actually 
doing a SDE solver.  

1:30 Looking at the shift work data, I plotted gamma vs time and I plotted sleep state.  In almost every long wake episode, gamma goes up substantially, but 
does not continue going up as long as the rat is awake.  It goes up and then turns off.  One time there was extended wake and gamma did not go up.  Active wake
vs. quiet wake may be important here.  This seems to be at odds with what the grant proposal and Janne's beta paper say. 

:TODO: Thursday:  try to figure out how the beta paper jives with what I'm seeing for gamma activity in shift work data.  Maybe try to find the actual 
.txt files that were used in the beta paper.  
 - try sleep depriving Costa model to see how everything changes: delta power, gamma, etc.  
 - keep reading Sorg/Wisor R01 to think of other modeling ideas.  It may be better to avoid EEG power measures and just 
   focus on sleep architecture?  

* Thursday, June 28, 2018
  I think I made a little progress on understanding the results in the beta paper.  I plotted gamma activity over the course of the entire recording
  for the whisking study (FS1\Jonathan Data\LactateWisking FFts andEdfs).  Here is what I think explains the plots showing gamma going down 
  during the 6 recovery sessions (between whisking). In fact, if you look at all of the data, gamma goes way up during the whisking and pretty much 
  stays elevated during the entire session (even between whisking).  What I see is that after a couple of whisking sessions the rat starts to have more NREM
  sleep between whisking.  During NREMS gamma activity always goes way down.  There is a little QW mixed in with the NREMS, but the gamma activity is so low 
  because of the NREMS that it barely rises during QW.  NREMS is dragging it lower as the whisking continues.  This explains why gamma power gets lower 
  with successive whisking sessions (and would probably happen during SD too).  So it isn't that gamma power generally decreases with SD or whisking, but that
  NREMS between sessions increases and that drives down gamma activity.  Check how this fits with grant proposal.  

  - I looked at all 22 recordings and 20 out of 22 followed this pattern.  Two files (7 and 8) actually showed completely opposite dynamics.  gammma was high during SWS 
  and low during all types of wakefulness.  I'm not sure what happened with those two files.  

  Statement from grant:  (first paragraph of second page)  "Our published data indicate that protracted wakefulness, a known trigger of oxidative stress in the 
  brain parenchyma [13,14] precipitates a reduction in gamma activity"  I need to think about this.  I'm not sure it is true.  I think protracted wake precipitates 
  more SWS between sessions and SWS substantially lowers gamma activity.  Enforced wakefulness (whisking, handling, etc) actually causes a shart rise in gamma activity. Being awake actually causes gamma to increase  (look at whisking sessions, gamma always goes up) 

  The pattern of high gamma during wake and low gamma during SWS was true for all recordings except for recordings 7 and 8 where the complete opposite was true: 
  when gamma when up the state was SWS, it went down during whisking.  

  * Friday, June 29, 2018
  One of the most striking patterns in these data is the fact that whenever gamma is low the mouse is in SWS and mostly true the other way:  if in SWS, gamma is low.  

* Monday, July 2, 2018
 I talked with Jonathan about gamma power and models.  He was encouraged by the output of the Costa model in terms of spectral power.  He said it isn't bad that 
 power in delta, alpha and beta all go up during SWS.  It's just that delta power is much higher than the others.  
 Normalize the power in each frequency band to the percentage of total power.  OR I could keep track of the ratios of gamma to delta for instance.  
 Jonathan drew a sketch of power vs frequency for wake, REMS and SWS and SWS has a very large and broad peak.  Larger than W or REMS. There is a lot of power 
 in SWS.  
 :TODO1: Check gamma in Costa model. We expect it to go down in SWS relative to wake.  
 :TODO2: Normalize power in each frequency band as a percentage of total power.  Check on how to normalize.  
 :TODO3:  Make a spectrogram of power vs frequency for the output of the Costa model for each of the 3 states.  Make sure it looks roughly like what Jonathan 
 drew for me.  :UPDATE:  I did this and the plots look funny.  For SWS and Wake there is a peak around 2 Hz, for REMS no peaks.  

:NOTE:  I will need to run Costa model with smaller time step. Currently dt = 0.01 seconds which is 100 Hz which means I can only resolve frequencies up to 50 Hz.
This will mean that simulations are significantly slower.  


* Tuesday, July 3, 2018
The fastest way to run the Costa model (in code that I wrote in Matlab) is to use sde_euler in matlab in windows.  It is faster than sde_solver that I wrote, but 
that was comparing equal time step sizes.  Since sde_solver should be more accurate, I could probably take a larger step size.  But remember that my step size
may be limited by the frequency range that we want to capture.  If we need to resolve frequencies up to 100 Hz we need to be sampling at at least 200 Hz which 
means a time step size of 0.005 seconds which is 5 ms.  

:Question:  Should I filter the output of the model to do a high-pass filter at 0.5 Hz?  Low-pass filter too?  

:TODO:  try using periodogram and pwelch to make spectral plots of data from a rodent recording.  Use JW code to merge txt and edf. :DONE:

periodogram.m seems to be very sensitive to the third argument. Figure out what to use here. Use length of signal.  Seems best.   

* Thursday, July 5, 2018
I'm comparing periodogram and pwelch to make spectral plots of experimental data for each sleep state.  Code is in check_spectral_output.m.  Periodogram
seems to be better:  more defined peaks, and it runs much faster.  Think about changing call to pwelch to periodogram in autoscoring code.  It may help.
:check: periodogram seems to be normalizing somehow.  When I plot all three states on the same graph, REMS has much more power than the other two, but even 
more than when I do all the data and don't separate states.  The second variable returned by Periodogram is the frequency which is normalized.  It seems to be 
normalizing by signal length which would shorter for the REMS case than the others because there are fewer REMS episodes than the others.  
How should I plot all three on the same graph?  I could multiply each by the number of epochs in that state.  THIS is wrong.  It normalized the frequency 
vector which I plot along the horizontal axis, not the vertical dimension.  

Well, the normalization issue aside, the periodogram seems to be working on the experimental data and it gives me what I expect:  SWS has a peak around 
1-4 Hz and wake and REMS both peak around 8 or 9 Hz.  

Costa model output:  generated from running his code (saved in Data directory):  Making the same periodogram plots required the use of a semilogy plot
since there was a huge amount of power near 0 Hz. On a semilogy plot, during wakefulness there is a bump near 2 Hz.  Why?  The other two stages
don't show any pattern, just gradually decreasing power as frequency increases.  No peaks.  

pwelch is showing me the same strange peak around 2 Hz.  

:TODO: Run my version of Costa's model:  either run_costa_model_using_sde_solver or run_costa_model_using_sde_euler and make sure that periodogram looks the same. 
If so, try changing dphi to see if that is what is setting the peak of the power at 2 Hz.  

:IDEA: maybe Costa did really run everything in ms and not seconds.  A time step of 0.1 ms is what the manuscript says.  BUT, his output has 8640000 samples 
for 24 hours which would be 0.01 seconds which is 10 ms.  Looks like Costa really does set dt to 0.1 ms.  Is he downsampling at some point? 
I figured this out.  In Cortex_SR_mex.cpp he runs the code with a time step of 0.1 ms, but he uses a parameter called red to only keep 1 out of every 100 samples. 
This is how it is run with a dt = 0.1 ms which is 10,000 steps per second, which is 10,000 Hz, but the output I get only looks like 100Hz if you look at number 
of samples in a 24 hour recording.  

Try to think of ways that I can write data to disk and then clear variables or something to save memory.     

:TRY:  1) Since Costa was running the code with dt=0.1 ms but only keeping 1 out of every 100 points it's as if we were running it with a much larger timestamp. 
          To really understand the spectral power in the output of his model, I need to run it with a relatively small time step and keep all the data.  
          Not throwing away data made MATLAB crash right away.  I tried running my version of it only for one hour of output and it said it ran out of Java
          heap space.  
        2) To address this:  try to chunk the data:  run the simulation for a small number of time steps and then save to disk, then erase.  
        3) Keep going on the GPU version of the code.  If it can really speed up simulation, it will be worth it.  


* Monday, July 9, 2018
I read the Ferguson and Skinner 2013 Frontiers paper more carefully and it could be helpful, but I think I would run into the same problems as the Costa model:
computational resources. They used BRIAN, but they also use a supercomputer.  They didn't have to include noise, because they simulated 500 cells.  Euler method. 
Her simulations were all for in vitro not in vivo.  Also in CA1. 

Any approach like Costa or Skinner seems like it will be unfeasible.  It takes many hours to do one run and I can't store the output variable for the EEG in 
one variable.  Only one hour of simulated data requires 2 chunks and 3.5G filesize in MATLAB.  When each run takes so much time and space, I can't imagine tuning 
parameters or making figures.  
Keep trying the GPU before I completely rule this out.  I spent some time on this today and it is still not looking promising.  Much slower than CPU.  I wrote a tiny
test and GPU is only faster if multiplying a relatively large matrix (500x500) 100s of times.  Making 100 calls to F Costa was a factor of 200 slower on the GPU 
compared to the CPU.  Perhaps bsxfun or something could make it fast, but I'm taking a break from it now.  


* Tuesday, July 10, 2018
Why can an edf file containing 3 or 4 signals, all sampled at 400 Hz for 48 hours be loaded into Matlab, but I can't run a simulation and 
store data for one variable at 100 Hz for more than a couple of hours?  What is the difference?  
A 26 hour edf is only 220 MB and can be loaded into matlab in 20-30 seconds using blockEdfLoad.m.  Once in matlab, the 400 Hz recording with 4 signals
26 hours only requires 905,200,448 bytes for all signals which is 905 MB.  Each trace has 36,500,000 elements.  The vector representing EEG in the Costa model
has 8,640,000 elements, butWhy does it require so much more space to set up a simple vector with

I spent quite a bit of time working on the Ferguson model in python and it is still not working. I made some progess, but I don't think it is worth continuing 
on.  Perhaps I can use some of their approach, but just do it in matlab.  Look up papers that cite Ferguson or other models of Parvalbumin-positive cells.  

* Wednesday, July 11, 2018
I'm trying to run run_costa_model_using_sde_euler.m with a time step of 1 ms rather than 0.1 ms.  1 ms would still give us roughly up to 500 Hz.  

I ran it once with time step of 10 ms and no noise and C_E, C_G, and C_A and h looked fine, but Vp blew up.  Probably because of too big time step. 
I'm running it again using time step of 1 ms.  

9:26: I'm running run_costa_model_using_sde_solver.m without noise for 24 hours just to make sure the solver is working correctly.  I should see the 
patterns of Vm from Costa model without noise:  4 large drops in Vm during the night.  THIS SEEMS TO BE WORKING.  TIME STEP OF 1 MS IS FINE.  

11:24 I wrote another version of the code that only keeps Vm and does not keep any other vectors, just scalars.  Profiling this code showed progressbar.m
as taking up a lot of time. Remove that from code and put in some comments so I know about how long it will take.   Also a couple of lines in F_Costa.m 
are pretty slow.  I'm not sure why.  

* Thursday, July 12, 2018
Just talked with Jonathan:  One idea to deal with the computational complexity:  Just think about the 6 hour segment in Janne's beta paper.  They did 
repeated Sleep deps and recovery and measured gamma during recovery each time.  I could simply model a short chunk of time (entire recovery or less) 
and measure gamma activity.  What we need is an input variable, like the homeostat.  The homeostat should be generally rising during these 
six hours, although it goes down a little during each recovery session.  We could simulate each small chunk of data between sleep deps and measure 
gamma power.  

:TODO: Run Costa model for a short time with a reasonably small time step and measure power. Compare a wake segment to the same amount of time in wake 
in a recording.  Do the same with SWS and REMS.  
The test experimental recording file that I was checking for gamma, delta, etc. was not good.  Most of it was not scored. 

4:30:  Matlab seems to be running super slowly now.  Try R2014 or something.  I don't know why LoadAndMerge is so much slower now.  Everything seems slower. 
And matlab takes up 22 GB of memory now just to load in an edf and txt file.  Something seems wrong.  

I ran the Costa model using my solver with a time step of 1 ms and made a periodogram using the exact same code that I used for the experimental data.  
Something is wrong because it is only nonzero at a frequency of 0 Hz.  If I only plot pxxAll(50:end) using fxAll(50:end) for the x-axis, the shape
and scale of the plot look reasonable.  I noticed that the y-axis was on a scale of hundreds when the real data were on a scale of 10^-6.  
I think filtering the output of the model to cut out frequencies below 0.5 Hz would be a great idea.  

:TODO: :MONDAY:  think about emailing Marcos, Jonathan, and Alex to sort out who is doing what and my ideas about other NSF grant.  


* Monday, July 16, 2018
I saved the 0.5 Hz High-pass filter as HP in the matlab workspace filter.mat in the directory Wisor_Sorg_R01_oxidation.  I'll need to load it before I can 
use it, but once I do.

Using the filter I set up, somehow MATLAB is normalizing and detrending the data.  Instead of starting around -60 and gradually rising, it starts near zero and stays 
there.  The histogram looks better than before, but peak is not matching up with wake from experimental data.  This could be because of detrending?  

One idea: code up how to get gamma power out of experimental EEG signal and make sure that it looks like what I saw when the gamma power was listed in a 
separate column in the .txt file:  when low it is always SWS, goes up with W or R.  Then I will know the code works for when I have the model working.  

* Tuesday, July 17, 2018
After filtering the data and adding the trend back in, I'm still seeing a huge spike near 0 Hz in the periodogram.  I thought this was filtered out. 

Detrending is key and is something I want to do.  Without detrending I was getting a huge spike a 0 Hz not matter how I filtered.  The filtered and 
detrended signal gives me a reasonable-looking periodogram.  
Some progress:  run_costa_model_using_sde_solver.m run for 10 minutes during wakefulness is now producing a periodogram that looks reasonable.  Also, 
alpha power is a little higher than delta power, but gamma is a factor of 10^3 smaller than alpha or delta.  
Try running the model for a segment of NREM sleep to run the same analysis.  
I may want to separate the code for running the simulation from the code for analyzing it.  I'm doing a lot of copying and pasting from run_costa_model_using_sde_solver.m
because I don't want to re-run the simulation. 
Figure out which I.C. I should use to simulate a NREM segment.  


* Wednesday, July 18, 2018
I have set up code to run the Costa model and a separate function to plot the output.  I am currently working on picking parameters for NREMS.  The 
first stab at it was close, but there were spikes similar to Figure 8 N2 panel, but the spikes were much larger (down to -120 mV).  If they are still 
present, see if the time step size is the issue:  try making dt=0.1 ms again, instead of 1 ms.  

Also, I may want to run the simulation for 24 hours using dt = 1 ms to see the correct output for all variables at all states.  This would help me really pick
accurate initial conditions for each state.  It may work (just take a long time) now that I have deleted that one huge file.  

The most recent run of Costa model for NREMS has an average Vp of around -52 mV rather than Costa's -60.  Also the large spikes are still there.  Try a smaller time 
step size.  
With the smaller time step size, the output was less noisy, but the spikes were still there.  If I zoom in on a 30-second segment it looks much like Figure 8 
in Costa, except that the average voltage is higher: -54 mV rather than -60 mV.  
I'm running it again with step size of 1 ms again to compare the outputs.   :DOTHIS:
4:45:  The REMS output looks pretty good.  Much like Costa's figure.  

* Thursday, July 19, 2018
The SWS output doesn't have any power below 4 Hz.  Check to see if it's the filter.  Check the other states too. REMS looks perfect in terms of the 
cutoff frequency.  Maybe issue is with the timestep.   SWS with dt=1 ms is fine.  The problem is with dt=0.1 because the filter assumes that dt=1.  

10:46 So far so good:  during wakefulness the periodogram has a broad peak with quite a bit of power between 5-10 Hz and alpha power is higher than
delta power.  During SWS the peak is much more narrow with a peak around near 0.5 Hz but a lot of power between 0.5 Hz and 2 Hz.  Delta power 
is higher than alpha power during SWS.  
The REMS data seems to have captured a transition to SWS so I should cut if off before I analyze it.  
One problem:  gamma power seems to be lower during wakefulness than it is during SWS. This is exactly opposite of what I expect.  Also, gamma power is much lower 
than delta or alpha power anytime.  I did a second run of SWS and it was just the same as the first.  Not a lot of variation from run to run.  

It would be nice to run a 24 hour simulation and plot gamma power for the entire time to see if gamma changes with sleep state sometimes or not.  

I'm checking the Costa output (from his C++ ).  This didn't help.  gamma is exactly zero everywhere.  This is probably because he threw away so much data that 
I can't get any meaningful spectral information out of it.  
Gamma power seems to be dependent on time step size.  Using the SWS data with dt = 0.1 ms reduced gamma power from about 4e-3 to 2e-3. 
Re-run the wake and REMS cases with dt=0.1 ms and use the elliptical filter. 
Run wake simulation for a long time so it really settles down to an equilibrium.  Then use the values at the end as I.C. for Wake instead of doing 
a transient and throwing out data.  :MAYBE: I could check Costa's output from his C++ code for this.  

* Monday, July 30, 2018
The long simulation I started before the week off did not save the variable Y (containing all the output data) because it was too large.  I have changed 
the script to use the -v7.3 flag so this doesn't happen again.  I managed to get the data just for the 8th variable in Y, Vp, by extracting it from the figure. 
This has been saved as Y in the .mat file Model_Output_20_Jul-2018__Wake.mat.  
Run analyze_Costa_model_output.m on these data to check gamma power.  
However, this will not help me in terms of choosing good initial conditions for wake.  

:IDEA: run my Neurobiology of Sleep... model of rodent sleep for the protocol done in the beta paper (Figure 1 in the grant) to get reasonable rodent 
sleep state data to work with.  This will be used as input to the model based on Costa et al.  Run the Neurobio simulations for as long as the experiments 
went.  The polyphasic nature of sleep may be important.  

2:30 When I changed dt from 1 ms to 0.1 ms the gamma power during wake went from around 2e-3 to 1e-3.  So gamma power is reduced when the time step 
size is reduced, regardless of sleep state.  Perhaps it is just important to be consistent in the time step. 
CHECK: does gamma power change as expected from SWS to Wake?   NO.  Using dt =0.1 ms gamma is higher during SWS than it is during Wake.  This is 
exactly backwards.  

Things to try: how sensitive is gamma to AMPA and GABA parameters?  If I change either of those, does this change the pattern of Gamma being higher during
SWS compared to wake?  

Think about other gamma models: with many cells.  See if any of these models generate reasonable gamma power. Check Gamma review again to see if any 
of these simpler models could work for us.   

* Wednesday, August 1, 2018
I just met with Jonathan to show him the gamma output of the Costa model and how it is opposite of what we want.  He suggested that I figure out exactly 
how SWA is generated in the model.  What drives it to increase during SWS?  This may be a clue about something that can be modified so gamma is 
lower during SWS as compared to wakefulness.  
Also, he suggested coding up the Ferguson/Skinner model with just a few cells rather than 500 like they do.  Perhaps only a few will be good enough.  

:TODO: check spectral power in specifically N3.  This is where the solution is close to Hopf and may give better power output.  

* Tuesday, August 7, 2018
I'm working on the Ferguson/Skinner model.  I have some code running on my laptop using a python 3.6 environment set up using conda.  In 
this environment, it already knows about Brian2 (but not Brian).  The code on ModelDB for the Ferguson Frontiers paper only simulated one cell,
but I found code for the Ferguson 2015 J Comp Neuro paper that uses the same equations and has code for a network.  However, it was for Brian,
not Brian2.  
1:38:  I managed to get this code running using Brian2. 
:TODO: put the relevant code from PYR_network_model.py into PV_model.py to simulate a network. 
       make sure I get results like her Frontiers paper.  
       export the data so I can load it in MATLAB
       Figure out and code up 

       It's not clear how to get an EEG-like signal out of Ferguson model output.  Do I do a weighted sum of synaptic currents like Jonathan talked
       about where cells are weighted based on location?  The frequencies shown in her paper are much higher than we are interested in.
       It does not look like they included noise in their simulations.  Perhaps I should.  
       One ide for EEG output:  Rulkov et al J Comp Neuro 2004 used the average of 100 cells in the middle of their 2D network to represent an LFP.  
       I could try something like this.  Perhaps average over all cells, just weigh the contribution of cells near the center (near electrode)


* Wednesday, August 8, 2018
I worked for a while on ADD_SCORING_TO_ZDB, but I couldn't seem to find a .zdb that had scoring.  Eventually I want to make one program that 
does the autoscoring and writes the new .zdb file, rather than two separate scripts.  


* Monday, August 13, 2018
Looking at the Ferguson model this morning.  It is running on my laptop with 1000 cells and 1.5 seconds of simulation takes about 30 seconds of CPU time. 
:TODO: for this model:  
          1) Can I run this in linux, and if so, is it faster? :ANSWER: runs in linux, but takes twice the time to run.  
          2) How to I model sleep state, or even GABA levels in this model? It does not seem to be as straight-forward as the Costa model.
          3)  

Looking at the Ferguson 2013 paper:  it looks like maybe in figure 6 panel A we could increase GABA (gsyn) which may dramatically increase 
network synchrony.  This increase in network synchrony may also give a decrease in gamma power.  ?? 


* Wednesday, August 15, 2018
I met Chris Fink for lunch today.  He is doing modeling of LFP using NEURON.  He says that you can't model LFP using a weighted average of lots of cells.
You need to do multi-compartment cells (he uses 3 compartments per cell) and hundreds of cells.  I did ask him if a network of cells is 
firing at a particular frequency, would that frequency show up in the LFP (or EEG)?  He said that it would, and the distortion due to tissue would be minimal. 

Maybe keep looking at the Izhikevich model code a bit.  It may be a good way to go.  Modify it for the Ferguson model.  Then check how gamma power changes with 
changing gsyn.  We expect an increase in GABA to cause a reduction in gamma power.   

Sould I completely give up on the Costa model?  The gamma activity was not promising.  Higher during SWS than during wake. I'm not sure 
how I could back out any sort of mechanism.  

Keep going trying to modify the Izhikevich model to use Ferguson's equations. I think this is promising.  

* Tuesday, August 21, 2018
Almost have the Ferguson model working in MATLAB as a modified Izhikevich.  However, the synaptic stuff doesn't seem to work since disconnecting 
all the cells from one another seems to have no effect on model output.  

Izhevich model is giving spikes that go way too high.  I could clip them off at 30mV like it looks like he did, but the Ferguson model doesn't seem
to clip them off unless it is done under the hood in Brian...

* Wednesday, August 22, 2018
Time step size is a big issue.  When I changed the code to use dt=0.01 ms instead of 1 ms, cell 20 spiked to around 0-10 mV and reset to -70 mV.  No really 
large spikes to 3000 mV.  Keep checking to see how small I need to go.  :TRY: Also, maybe try using ode45 or something.  It may actually be faster if it can use adaptive time-stepping.
The problem is that now I need to think more about how to do the T for one ms.  

12:54: I tried a timestep of 0.001 ms and the spike peaks are a bit shorter (near 0 like Ferguson), but the frequency is exactly the same.  I'm going to stick with 0.01 ms from now on.

Maybe RK4 would allow for a larger timestep....

The firing rate of my cell using Izhikevich_modified is higher than what I get out of PV_model.py (I get about 4 spikes every 100 ms and she gets about 2.  In 1 second I get about 48 spikes,
she gets about 24 spikes)
NOthing seems to change when I make gsyn=0.  I'm getting no input from synapses. 

I'm working on getting the frequency correct for one cell, so I turned off all connectivity.  I changed the initial condition for u to be zero instead of b*v like Izhevich had.  Also, 
I changed d from 0.1 to 10.  The graph of u vs time did not look like figure 2 in Izhevich's paper. 

:NOTE:  The network without connectivity is spiking at a faster frequency than Ferguson, but let's leave it for now.  I will probably need to adjust parameters anyway to match our 
PV cell data.  Start working on getting the connectivity issues sorted out.  

:IDEA:  Isyn should not be reset to 0 each time step.  It should be added to every cell every timestep.  s is the only variable that needs to worry about what has happened 
pre-synaptically.   I fixed this. 
Why is s not going above 0.06?  It saturates there even though I turned off the s_too_high code.  alpha/(alpha+beta) = 0.869 it is not making it to this value. :FIXED: now it is. 
T seems to be behaving correctly.  Why isn't s continuing to grow?  
I may also need to make Isyn a matrix, not a vector.  
:FIXEDONEISSUE: the equation for s was missing a parenthesis.  It is correct now.  keep testing.  Plot of s vs time looks much better.  

* Thursday, August 23, 2018
Code up the phi coherence measure in Ferguson paper.  Test it on my Izhikevich output.  

I'm not getting a lot of noise in my simulation output.  with gsyn=0, changing Iapp to a constant makes almost no difference.  

10:26: In python, changing Iapp to be a constant rather than normally distributed made the output look much like my output using Iapp constant or random (very coherent 
firing across all cells)  Why?  
10:33 I confirmed this.  Also, with Iapp being constant, the firing frequency matches between python and matlab.  

3:00 I installed HNN, a new simulator for generating EEG-like activity.  It may be promising, but I feel that there is too much going on under the hood for it to be useful.  
How would I add anything like sleep state?  Sleep deprivation?   

* Friday, August 24, 2018
I just met with Jonathan.  Let's keep going with the Ferguson approach.  I think it has promise.  Jonathan said that even though their paper was for CA1, we can 
probably just write a paragraph in the discussion talking about medial prefrontal cortex vs hippocampus.  We are studying the medial prefrontal cortex.  

I think it would be worth talking to Chris Fink about the idea of synapses and equations 1 and 2.  If I need to modify the params a bit from Ferguson's paper I think that 
is fine.  I am basically starting with the Izhevich model anyway so I'm allowed to modify it a bit to suit our needs.  


* Thursday, September 6, 2018
I talked with Jonathan today about grant ideas, specifically Darpa.  He pitched an idea to me that he has been thinking about for a long time.  The idea is that with EEG data, 
pupil data, and some measure of skin stress level we can determine when someone is going into a microsleep or arousal lapse.  The idea being that if two soldiers are together, 
and one starts to lapse into microsleep, information should be sent from one soldier to the other.  
Here is a proof of concept that we would need:  Show a subject moving bars like Kit shows the mice.  Show them for 30 minutes.  After those 30 minutes cells in the subjects 
visual cortex show a preference for the stimulus moving at that particular angle.  However, if a person is drowsy, you can show them the same stimulus for the same time and their visual
cortex does not develop the same preference?  Look up the OSRP that is talked about in the Wisor/Sorg grant.  This sounds like sleep-dependent plasticity.  Is the point of the 
proof of concept to show that we can tell when the subject is sleepy?  
Two people in the same room seeing the same stimulus, one is rested and one is sleepy.  The rested subject would show aquisition of memory, exhibited how?  The sleepy 
subject would not show the learning?    
I need to draft an email to Hans to see if he would be interested in at least allowing us to do the human experiments.  Also, I need to find an appropriate Darpa grant and include 
the link in the email. 

* Thursday, September 13, 2018
  I met with Chris Fink this morning at GU to talk about connecting cells in a manner similar to Ferguson et al.  He said that for cells receiving synaptic input from 
  more than one cell, I could add terms on.  For instance, if cell 2 receives input from cells 4 and 3, set up a variable s23 and s24 or something and add two terms onto
  the equation for cell 2: gsyn*s23*(v2-Esyn) + gsyn*s24*(v2-Esyn).  This is equivalent to: gsyn*(s23+s24)*(v2-Esyn).  This seems to make sense.  Also, I should probably 
  cap the s term.  I know each variable s is capped, but should I also put a cap on the sum?  This may be big if a cell is receiving synaptic input from many other cells. 

  Also, I should look in Dayan and Abbot.  I'm sure they have something related to this.  Chris also talked about another way to do it, where if 2 cells receive input
  from the same presynaptic cell, the s variables must be the same, so I could think of this s as being presynaptic, not post-synaptic.  

  I think the way I would prefer to proceed is the following:  Once I've determined connectivity, set up a connectivity matrix S so S(i,j) has a non-zero 
  entry if cell i is connected to cell j (i is presynaptic, j is postsynaptic).  Wait:  it doesn't need to be a matrix, it could just be a vector, but some 
  entries will not be 

  :IDEA: Perhaps is one cell is post-synaptic to multiple other cells, I should still use just one s variable for that cell.  (s is post-synaptic, after all).
  The way that multiple cells can come into the mix, is through [T].  T becomes 1 when ANY of the presynaptic cells fires.  This may be strange when more than 
  one presynaptic cells fire within one ms of each other, but I suppose that could be saturation too. 

  looking at the code, I think I may not need the code in lines 74-80.  CORRECTION: I do need them, but I have modified them.  Also, this code only seems to update 
  Isyn for cells that had a pre-syn cell fire, but really s (and Isyn) need to be updated every step for every cell regardless of whether the presynpatic cell 
  fired or not.  the only difference between having a presynpatic cell fire or not is in s.  This was because not every cell is even connected to a presynaptic
  cell.  If not connected, then it should now h

  11:37 I coded up the new way to doing the s variable,  but there still seems to be an awful lot of synchrony.  All cells fire together with a bit of noise.  

  * Thursday, September 27, 2018
  I'm trying to simplify down to a small network to make sure I'm doing what I expect.  I did check that on average each pre-synaptic cell is connected
  to about 60 post-synaptic cells.  This matches the paper.  

  10:17: I simplified the network and only had one connection: cell 1 is presynaptic to cell 5.  I turned off all the Iapp, except to cell 1.  I wanted to test 
  if the one synapse can make cell 5 fire even if cell 5 is getting no external input, just the synaptic input from cell 1.  Only cell 1 fired, and only because
  of Iapp.  Cell 5 never fired, even though it is connected synaptically to cell 1.  Why not?  

  When a pre-syn cell fires, the post-syn cell turns on the s variable, but it seems to stay constant, in this case at 0.0370.  Why doesn't it grow toward 1?  

  T looks OK, s looks OK, Isyn is always 0.  Figure out why.  

  * Thursday, October 11, 2018
  It seemed for a moment that the Izhevich model could not handle the case where more than one cell fires in one timestep.  Now I see that this is not the case. 
  If more than one cell fires in one time step, that timestep is repeated in the "firings":  2 or more rows will have the same entry in the left column and different
  entries in the right column.  

  Isyn is 10 orders of magnitude smaller than than Iapp.  This may explain why it is not doing anything.  I checked the units again, and they all check out: Both
  Isyn and Iapplied are in units of pA.  

  I just ran the python code (after some fixing) and it seems like the python code and my matlab code are matching up, but neither is giving me what I would expect. 
  In both cases, all the cells fire synchronously giving about 24 spikes per second.  
  I set the gsyn to 0 in the python code and it made no change to the output, just like when I make the same change in my matlab code: no change to output. 

  11:12: My matlab code is now looking pretty good.  With gsyn set to 0 I get coherent firing, just like the python code with 23 spikes per second.  With gsyn
  set to 4.8, the cells all start in sync but then desynchronize by about 750 ms.  This may be good enough to go with.  

  
  * Thursday, October 25, 2018
  I had some really strange issues with updating Izhikebich_modified.m today.  I changed code in the file, but when I run it those new changes don't run. 
  I restarted hoping that would help.  Also, the directory called two-photon-stuff no longer exists.  That is strange. 

  Use nchoosek.m to set up the matrix of all possible combos of two cells to compute phi_ij and phi.  
  
  11:11 I ran the model with gsyn = 1.5 nS and Iapp=595 pA to reproduce the lower inset panel in Ferguson Figure 5 panel A, but the output did not look
  as random as what they show in the figure.  I did get a very different PSD plot with a clear max frequency at 192.5 Hz.  Keep checking to make sure 
  the model is working correctly.  

  starting to code up phi calculation.  Needed to keep v at each time step rather than overwriting.  This required some changes to Izhikevich_modified.m. 


  * Monday, October 29, 2018
  My goal today was to code up phi calculuation, but first I had to fix some bugs introduced by keeping v at every time step rather than overwriting. 
  One issue was in resetting v and u and T and setting k if cells had fired.  If none fired, now I get an error.  I fixed this and was hopeful that 
  this would improve the output of the model, but instead it made it worse. In trying to recreate the lower inset of panel A in figure 5, I now get really
  synchronized output.  Very synchronized, almost no noise.  Why is this happening? and what changed by simply keeping v at every step instead of overwriting? 

  11:57  Changing gsyn to 0 made no change to the raster plot or the frequency plot


  I tried changing connectivity to 90% instead of 12% and all but about 15 cells are still really synchronized. When I made connectivity zero, all 
  cells synchronized (with noise).  Check relative size of synaptic current in Izhevich paper and compare to mine.  For me I think s is way smaller 
  than the other variables so that may be why synaptic currents seem to have no impact on firing.  

  2:13 maximum Isyn during spiking is 39.1191, which is a lot smaller than Iapp. 

  One idea: perhaps it is how I keep s from getting too large.  In my update equation for s I use the "any" command.  Perhaps I should sum the 
  inputs or something.  

  * Tuesday, October 30, 2018
  To get something working: try using the simpler synaptic connection model like Izhikevich uses in his code.  Perhaps I can modify it to make connections to
  only 12% of other cells or so.  

  Try coding up the synaptic connections using equations 4 and 5.  That may give me more flexibility in adding up conductances from multiple synapses.

  11:00 Even with the new way of updating s, with Iapp set to 150 (which should give no synchrony) there was a ton of synchrony.  All cells firing at 
  the same time just like before.  
With so few connections, how do any simulations go to unsyncronized firing?  What I'm seeing actually makes sense in some ways:  If only 12% are connected, 
and all cells start with same I.C. (with noise) and receive same Iapp (with noise) they will all fire in the same way.  Try using the simpler way that Izhivich
does in his code.  Use S(find(S>0.12))=0 to set all but 12% of the values to 0.  

11:35 I realized I had set connectivity to 90% so I set it back to 12%, but it didn't make a difference.  Same crazy synchronization.  

* Thursday, November 1, 2018
Idea: it seems like the synaptic current is way too small (compared to Iapp).  Perhaps a typo in paper?  Try setting it to a much larger number. 

8:50 I tried setting gsyn to 15 rather than 1.5 and there was a little more desynchrony, but not much.  try 150.  

YES!  with gsyn set to 150 and Iapp set to 150 I finally get completely random firing, much like the lower inset in panel A of figure 5 in Ferguson.  The units
must have been off or there was a major typo in the paper.  CHECK THIS
Now I'm trying to increase Iapp to 600 to see if I can get coherent firing again.  
YES! When I switched Iapp to 600 I see nice regular firing, just like the top inset in panel A of Figure 5 at about the same frequency as they have!! 

Next: code up coherence measure so I can see if I am roughly reproducing Figure 5 panel A.   

10:34 I have coded up the coherence measure and it seems to work, but I got a phi of 0.84 for the upper panel in panel A.  However, I am using tau = 1 ms 
rather than what they used (1/coherent freq).  That may explain the difference.  It may be worth checking, or I could just check the other case with 
low coherence and make sure it give me a low phi value.  

Need to modify compute_phi to handle the case when a cell does not fire at all during the last 500 ms of the simulation.  FIXED: I used the 'omitnan' flag 
in the call to mean at the very end.  Now I get a phi of 0.0114 when gsyn=150 and Iapp=150. this completely jives with Figure 5.  Low synchrony if Iapp 
is really low. 

The last thing I was doing was some profiling.  I found that the line with if any(....) is requiring about 80% of processor time.  I started to write up a 
test for speed between any.m and sum.m  

* Tuesday, November 6, 2018
I wrote up a little test to compare the speed of if any vs sum and "if any" was actually a little faster than sum.  So for now I will stick with that, 
but I'm guessing there is some way to make that faster.  

11:00 AM I have coded up compute_gamma_power, but so far I'm getting zeros for all of the frequency bands.  I wonder if the way I'm computing deltaIdx, etc
is different in Matlab 2018.  I shouldn't be getting all zeros for each frequency band.  Also check units.  Freqs_new doesn't seem to be in correct units 
or is not broken down enough. there aren't any between 0 and 195 for instance.  

* Thursday, November 15, 2018
I think I fixed the issue with the frequency bands.  I needed to tell pwelch which frequecies to output.  
More testing: 10:55: I am doing a run with gsyn = 600 and Iapp=600 and I get incoherent firing, just like I hoped.  phi = 0.05  average gamma power = 0.08
with gsyn = 150, Iapp=600 gives coherent firing.  phi = 0.844, average gamma power = 10.34  
This is good.  So for a constant value of Iapp, by simply reducing the strength of inhibitory connections between the cells, it can increase gamma power significantly.

Think about what to do next:  Should I try a range of gsyn and Iapp values and plot gamma power?  I could check sensitivity to standard deviation of Iapp too.  Go back to 
Wisor/Sorg grant proposal to see what I should do next.  


* Sunday, November 25, 2018
working on Ashley's stuff.  I could not get the executable from Daniel to work.  When I try to select files, nothing happens. 

* Tuesday, November 27, 2018
At WSU this morning.  I spoke with Jonathan about Ashley's project and I should focus on getting peaks to Jonathan for him to analyze.  
Use Daniel's program first.  

I can see all the windows in Daniels program, and it seems to be running, but I'm not getting anything useful out of Daniel's program so far.  Gets stuck on "detrending" and then if I go to export tab, it says it is exporting, but the file never appears.  

If finally got Daniels program to work only if I use "movmad" option for detrending.  I saved one file 


* Tuesday, December 4, 2018
I've been messing with the plotting stuff for the astrocytes data.  The code doesn't produce good output so far on the full dataset, I think because there are big jumps in 
the time in the .xlsx file.  It still works on the sleepstages_sample file.  
I think the best way to move forward is to work with finding peaks.  


On the Barb Sorg project:  Re-reading the grant proposal and thinking about how I can contribute.  Do I scale up the Ferguson model in some way?  I had written in my copy of the grant proposal that the experiments for Aim 1 should be carried out fall 2018.  
:TODO: Meet with Priyanka to see if the data for the experiments in Aim 1 are stored here:  Bushana/NAC Sleep These datasets may give me information that I can use to test how sleep architecture changes with changes to PNN.  Also, I could maybe use Process S to quantify rise and fall times of SWA (see "Expected outcome for Experiment 1" in proposal.  )

* Thursday, December 6, 2018
I met with Priyanka this morning and asked her which Aims of the grant include polysomnography.  Aim 1 does.  Aim 2A does not seem to.  Aim 2B will because it's two photon.  Aim 3 does not.  Aim 4 will have EEG since it is imaging.  

:DATA_LOCATION: She pointed me to some data she has already collected that is not really part of any of the aims in the proposal.  Bushana\NAC Sleep\all hi-dose expt\
She has done autoscoring (and fixed some output) and she is happy with it.    Autoscore_Input_log.txt lists which EEG was used and whether EMG was used or not.  

For the protocol for the data in all_hi-dose_expt, see the poster GRC Poster 03-14-18.pptx in Bushana folder.  Each recording contains either baseline day + 6-hr sleep dep (as shown in poster) where during the sleep dep the animal was injected either with saline or with NAC.  

To find out when the injections happened, look for the artifacts marked X starting near 6:00 AM, but they are probably around 6:20 or so.  

* Wednesday, December 12, 2018
Looking at Priyanka's poster: She shows percentage of each sleep state in each hour during SD and after SD for the control group and NAC group (Fig 4).  They do not see much 
of a difference between the two groups, but I'm wondering if it would be helpful to look at episode duration and number of bouts as well.  I could generate this experimental data 
using SleepReport and then if something interesting shows up I can try to use my shift work model to simulate it.  
It looks like most of the interesting differences between the NAC and control groups happen in gamma power and delta power, so I may need to use the Ferguson model eventually.  

* Thursday, December 13, 2018
I met with Jonathan this morning to go over his ROI pattern-finding code.  He sent me a link.  He would like to wrap this up next week.  I should take a look at it, fix errors that
I may find and run it on the full recording, not just the sample.  

I am modifying the code so it works with R2018 or R2015, since loading tables is so much faster and cleaner in R2018.  Check how Jonathan sets up the variable Stage, because I don't quite get
it and I need to make sure that the R2018 version of the code does the same thing.  


* Tuesday, January 8, 2019
I met with Jonathan and Priyanka to talk about the Chen et al NEURON 2017 paper and modeling opportunities.  They were enthusiastic about the modeling approach.  I do need to read the paper more carefully to see about if my understanding of the graphical abstract is correct, but I think it is.  I put arrows in my printout of the paper to show which sections I need to read carefully to constrain the models for SOM cells and PC cells and PV cells.  
:TODO: Think about the structure of the program: should I have one function that updates PV cells, one for SOM cells, and one for PC cells?  

* Friday, January 11, 2019
I thinking about how to model the pyramidal cells and SOM (somatostatin) cells.  I found this paper Mazzoni et al 2015 that uses leaky int-n-fire models.  It may be helpful.  

* Tuesday, January 22, 2019
Talk to Jonathan about the ROI stuff.  The code ran on UltraRoss, but I am not understanding the results.  ROIFiringSequence is not making sense to me.  

* Thursday, January 24, 2019
I just talked with Jonathan about the ROI stuff.  Looking at ROIFiringSequence{1,1} each column does refer to a distinct group of 6 cells.  Each
row is another time that group of 6 fired together.  I looked up tierank and I think I understand it now. 
Keep going with my idea written on paper to convert to ABCDEF and store all the sequences in cell arrays (set up by arousal state and baseline 
vs not.) then I think I should be able to carry out the analysis I have written on the sheet on the left.  I still need to work through a couple 
of quirky issues with cell arrays in matlab. 

:NOTE: I have moved comments about the Frank lab research to another file: Research Journal for work with Frank lab starting.org.  It can be found in MATLAB/Rempe. 

* Friday, February 1, 2019
Working on PV_model.m to check it and maybe speed it up before I work on PV_PC_SOM model. 
I'm working on a new way to make the raster plot since what I had before was really slow.  DONE.  Somewhat faster.  
One issue to think about:  If a voltage reaches 2.5, it gets reset to -70 and by reset I mean changed to -70 rather than 2.5.  This will affect the average voltage plot. 
A better way would be to let it go to 2.5 and then set the NEXT value to -70 instead of overwriting the current value to -70. I did  not pursue this, but I set up another
vector that has the voltage before it was reset.  

I'm calculating the average voltage differently now.  This didn't work.   The plots overlay.  V gets reset so I guess v_with_spikes does too.  

* Monday, February 4, 2019
v_with_spikes does seem to reach 2.5, at least at line 96 of the code.  Does it get reset back to a lower value too?  NO. 
AHA:  I think it is actually working correctly.  What I am plotting is the AVERAGE membrane potential over all cells.  In this scenario the cells are mostly 
firing together, but if you look closely, not ALL cells are firing at exactly the same time.  Since some are at rest near -60, the AVERAGE membrane 
potential is near -8 mV and is not very different from not including the spikes.  